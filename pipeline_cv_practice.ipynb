{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad8e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1: Build Your First Pipeline\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 2: Understand fit() vs transform()\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 3: Implement Time-Series Cross-Validation\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 4: Detect Data Leakage\n",
      "================================================================================\n",
      "\n",
      "--- Approach A ---\n",
      "Approach A Accuracy: 0.6686\n",
      "\n",
      "--- Approach B ---\n",
      "Approach B Accuracy: 0.6686\n",
      "\n",
      "‚úì Which approach is correct? Think about it!\n",
      "  Hint: Which scaler sees test data during training?\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 5: Hyperparameter Tuning with GridSearchCV\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 6: Compare Multiple Models\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXERCISE 7: Challenge - Production-Ready Pipeline\n",
      "================================================================================\n",
      "\n",
      "‚úì Complete this challenge to master Pipelines & CV!\n",
      "  Hints:\n",
      "  1. Use features from FEATURES_FULL in baseline model\n",
      "  2. Tune max_depth, learning_rate, n_estimators\n",
      "  3. Use TimeSeriesSplit for CV\n",
      "  4. Evaluate ONCE on test set\n",
      "\n",
      "================================================================================\n",
      "Ready to check your solutions?\n",
      "Uncomment the code blocks above and run each exercise!\n",
      "================================================================================\n",
      "\n",
      "üí° Learning Tips:\n",
      "1. Work through exercises in order\n",
      "2. Uncomment code blocks one at a time\n",
      "3. Modify parameters to see effects\n",
      "4. Compare results with expected values\n",
      "5. Ask questions when stuck!\n",
      "\n",
      "‚ú® You've got this! Let's build some models! üèÄ\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hands-On Practice: Pipelines & Cross-Validation\n",
    "================================================\n",
    "\n",
    "Work through these exercises to master the concepts.\n",
    "Each exercise builds on the previous one.\n",
    "\n",
    "Author: Oleksandr\n",
    "Date: November 28, 2024\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 1: Basic Pipeline Construction\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 1: Build Your First Pipeline\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Create a pipeline with:\n",
    "1. SimpleImputer (median strategy)\n",
    "2. DecisionTreeClassifier (max_depth=5)\n",
    "\n",
    "Then fit and evaluate it.\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "NBA_DATA_PATH = 'C:\\\\Users\\\\userPC\\\\projects\\\\predictive-modeling-platform\\\\data\\\\processed\\\\nba\\\\final\\\\nba_train_data_enhanced.csv'\n",
    "df = pd.read_csv(NBA_DATA_PATH)\n",
    "df = df.dropna(subset=['HOME_WIN'])\n",
    "\n",
    "# Basic features\n",
    "features = ['NET_RATING_DIFF', 'REST_ADVANTAGE']\n",
    "X = df[features]\n",
    "y = df['HOME_WIN']\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# Create pipeline named 'my_first_pipeline'\n",
    "# Step 1: 'imputer' - SimpleImputer with strategy='median'\n",
    "# Step 2: 'classifier' - DecisionTreeClassifier with max_depth=5\n",
    "\n",
    "my_first_pipeline = None  # Replace with your pipeline\n",
    "\n",
    "# Uncomment to test:\n",
    "# # Simple train/test split\n",
    "# split_idx = int(0.8 * len(df))\n",
    "# X_train = X.iloc[:split_idx]\n",
    "# y_train = y.iloc[:split_idx]\n",
    "# X_test = X.iloc[split_idx:]\n",
    "# y_test = y.iloc[split_idx:]\n",
    "# \n",
    "# # Fit and evaluate\n",
    "# my_first_pipeline.fit(X_train, y_train)\n",
    "# accuracy = my_first_pipeline.score(X_test, y_test)\n",
    "# print(f\"\\n‚úì Pipeline accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 2: Understanding fit() vs transform()\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 2: Understand fit() vs transform()\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Manually create and apply a scaler to understand the process.\n",
    "Compare statistics learned from train vs test.\n",
    "\"\"\"\n",
    "\n",
    "# Create small dataset\n",
    "X_train_sample = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
    "X_test_sample = np.array([[5, 10], [6, 12]])\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Create a StandardScaler\n",
    "# 2. Fit it on X_train_sample (learns mean and std)\n",
    "# 3. Transform X_train_sample using the fitted scaler\n",
    "# 4. Transform X_test_sample using the SAME fitted scaler\n",
    "# 5. Print the mean and std learned by the scaler\n",
    "\n",
    "# Uncomment to test:\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train_sample)\n",
    "# \n",
    "# X_train_scaled = scaler.transform(X_train_sample)\n",
    "# X_test_scaled = scaler.transform(X_test_sample)\n",
    "# \n",
    "# print(f\"\\nTrained on: {X_train_sample}\")\n",
    "# print(f\"Learned Mean: {scaler.mean_}\")\n",
    "# print(f\"Learned Std: {scaler.scale_}\")\n",
    "# print(f\"\\nTrain Scaled:\\n{X_train_scaled}\")\n",
    "# print(f\"\\nTest Scaled:\\n{X_test_scaled}\")\n",
    "# print(\"\\n‚úì Notice: Test data scaled using TRAIN statistics!\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 3: Time-Series Cross-Validation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 3: Implement Time-Series Cross-Validation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Use TimeSeriesSplit to evaluate a model with 3 folds.\n",
    "Print the performance for each fold.\n",
    "\"\"\"\n",
    "\n",
    "# Load full dataset\n",
    "features = ['NET_RATING_DIFF', 'HOME_B2B', 'AWAY_B2B']\n",
    "X = df[features]\n",
    "y = df['HOME_WIN']\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=4, random_state=42))\n",
    "])\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Create TimeSeriesSplit with n_splits=3\n",
    "# 2. Use cross_validate to evaluate the pipeline\n",
    "# 3. Print mean and std of test scores\n",
    "\n",
    "# Uncomment to test:\n",
    "# from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "# \n",
    "# tscv = TimeSeriesSplit(n_splits=3)\n",
    "# \n",
    "# cv_results = cross_validate(\n",
    "#     pipeline, X, y,\n",
    "#     cv=tscv,\n",
    "#     scoring='accuracy',\n",
    "#     return_train_score=True\n",
    "# )\n",
    "# \n",
    "# print(f\"\\nCV Accuracy: {cv_results['test_score'].mean():.4f} (¬±{cv_results['test_score'].std():.4f})\")\n",
    "# print(f\"\\nFold Results:\")\n",
    "# for i, (train_score, test_score) in enumerate(zip(cv_results['train_score'], cv_results['test_score'])):\n",
    "#     print(f\"  Fold {i+1}: Train={train_score:.4f}, Test={test_score:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 4: Detecting Data Leakage\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 4: Detect Data Leakage\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Compare two approaches and identify which one has data leakage.\n",
    "\"\"\"\n",
    "\n",
    "# Approach A: Fit scaler on all data\n",
    "print(\"\\n--- Approach A ---\")\n",
    "scaler_a = StandardScaler()\n",
    "X_scaled_a = scaler_a.fit_transform(X)  # Fits on ALL data\n",
    "\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train_a = X_scaled_a[:split_idx]\n",
    "X_test_a = X_scaled_a[split_idx:]\n",
    "\n",
    "model_a = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "model_a.fit(X_train_a, y.iloc[:split_idx])\n",
    "accuracy_a = model_a.score(X_test_a, y.iloc[split_idx:])\n",
    "\n",
    "print(f\"Approach A Accuracy: {accuracy_a:.4f}\")\n",
    "\n",
    "# Approach B: Fit scaler only on training data\n",
    "print(\"\\n--- Approach B ---\")\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train_b = X.iloc[:split_idx]\n",
    "X_test_b = X.iloc[split_idx:]\n",
    "y_train_b = y.iloc[:split_idx]\n",
    "y_test_b = y.iloc[split_idx:]\n",
    "\n",
    "scaler_b = StandardScaler()\n",
    "scaler_b.fit(X_train_b)  # Fits only on TRAIN data\n",
    "X_train_b_scaled = scaler_b.transform(X_train_b)\n",
    "X_test_b_scaled = scaler_b.transform(X_test_b)\n",
    "\n",
    "model_b = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "model_b.fit(X_train_b_scaled, y_train_b)\n",
    "accuracy_b = model_b.score(X_test_b_scaled, y_test_b)\n",
    "\n",
    "print(f\"Approach B Accuracy: {accuracy_b:.4f}\")\n",
    "\n",
    "# YOUR ANSWER HERE:\n",
    "# Which approach has data leakage? Why?\n",
    "# Which accuracy is more reliable?\n",
    "\n",
    "print(\"\\n‚úì Which approach is correct? Think about it!\")\n",
    "print(\"  Hint: Which scaler sees test data during training?\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 5: GridSearchCV with Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 5: Hyperparameter Tuning with GridSearchCV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Use GridSearchCV to find the best max_depth for DecisionTreeClassifier.\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data\n",
    "features = ['NET_RATING_DIFF', 'REST_ADVANTAGE', 'HOME_B2B', 'AWAY_B2B']\n",
    "X = df[features]\n",
    "y = df['HOME_WIN']\n",
    "\n",
    "# Train/test split (chronological)\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train = X.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Create a pipeline with SimpleImputer and DecisionTreeClassifier\n",
    "# 2. Define param_grid testing max_depth values [3, 4, 5, 6]\n",
    "# 3. Use GridSearchCV with TimeSeriesSplit(n_splits=3)\n",
    "# 4. Fit on training data\n",
    "# 5. Evaluate on test data\n",
    "# 6. Print best parameters and test accuracy\n",
    "\n",
    "# Uncomment to test:\n",
    "# pipeline = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "# ])\n",
    "# \n",
    "# param_grid = {\n",
    "#     'classifier__max_depth': [3, 4, 5, 6]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     param_grid,\n",
    "#     cv=TimeSeriesSplit(n_splits=3),\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# \n",
    "# grid_search.fit(X_train, y_train)\n",
    "# \n",
    "# print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "# \n",
    "# # Test set evaluation\n",
    "# best_pipeline = grid_search.best_estimator_\n",
    "# test_accuracy = best_pipeline.score(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 6: Complete Model Comparison\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 6: Compare Multiple Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Compare Decision Tree vs XGBoost using time-series CV.\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data\n",
    "features = [\n",
    "    'NET_RATING_DIFF',\n",
    "    'EFG_PCT_DIFF',\n",
    "    'TOV_PCT_DIFF',\n",
    "    'OREB_PCT_DIFF',\n",
    "    'FTA_RATE_DIFF',\n",
    "    'REST_ADVANTAGE'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['HOME_WIN']\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Create two pipelines:\n",
    "#    - Decision Tree (max_depth=5)\n",
    "#    - XGBoost (n_estimators=100, max_depth=4, learning_rate=0.1)\n",
    "# 2. Evaluate both using TimeSeriesSplit(n_splits=5)\n",
    "# 3. Compare accuracy and log_loss\n",
    "# 4. Determine which is better\n",
    "\n",
    "# Uncomment to test:\n",
    "# from sklearn.metrics import make_scorer, log_loss as sklearn_log_loss\n",
    "# \n",
    "# # Decision Tree Pipeline\n",
    "# dt_pipeline = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('classifier', DecisionTreeClassifier(max_depth=5, random_state=42))\n",
    "# ])\n",
    "# \n",
    "# # XGBoost Pipeline\n",
    "# xgb_pipeline = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('classifier', XGBClassifier(\n",
    "#         n_estimators=100,\n",
    "#         max_depth=4,\n",
    "#         learning_rate=0.1,\n",
    "#         random_state=42,\n",
    "#         eval_metric='logloss'\n",
    "#     ))\n",
    "# ])\n",
    "# \n",
    "# # Scoring metrics\n",
    "# scoring = {\n",
    "#     'accuracy': 'accuracy',\n",
    "#     'log_loss': 'neg_log_loss'\n",
    "# }\n",
    "# \n",
    "# # Time-series CV\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# \n",
    "# # Evaluate Decision Tree\n",
    "# dt_cv = cross_validate(dt_pipeline, X, y, cv=tscv, scoring=scoring)\n",
    "# print(\"\\nDecision Tree Results:\")\n",
    "# print(f\"  Accuracy:  {dt_cv['test_accuracy'].mean():.4f} (¬±{dt_cv['test_accuracy'].std():.4f})\")\n",
    "# print(f\"  Log Loss:  {-dt_cv['test_log_loss'].mean():.4f} (¬±{dt_cv['test_log_loss'].std():.4f})\")\n",
    "# \n",
    "# # Evaluate XGBoost\n",
    "# xgb_cv = cross_validate(xgb_pipeline, X, y, cv=tscv, scoring=scoring)\n",
    "# print(\"\\nXGBoost Results:\")\n",
    "# print(f\"  Accuracy:  {xgb_cv['test_accuracy'].mean():.4f} (¬±{xgb_cv['test_accuracy'].std():.4f})\")\n",
    "# print(f\"  Log Loss:  {-xgb_cv['test_log_loss'].mean():.4f} (¬±{xgb_cv['test_log_loss'].std():.4f})\")\n",
    "# \n",
    "# # Winner\n",
    "# if -xgb_cv['test_log_loss'].mean() < -dt_cv['test_log_loss'].mean():\n",
    "#     print(\"\\n‚úì Winner: XGBoost (lower log loss is better)\")\n",
    "# else:\n",
    "#     print(\"\\n‚úì Winner: Decision Tree (lower log loss is better)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 7: Challenge - Build Production Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 7: Challenge - Production-Ready Pipeline\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\"\"\"\n",
    "TASK: Create a complete production pipeline that:\n",
    "1. Uses all relevant features\n",
    "2. Tunes XGBoost hyperparameters\n",
    "3. Evaluates on hold-out test set\n",
    "4. Calculates Brier Skill Score\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# Build the complete pipeline following best practices:\n",
    "# - Chronological train/val/test split (70/15/15)\n",
    "# - Grid search on validation set\n",
    "# - Final evaluation on test set\n",
    "# - Report all metrics\n",
    "\n",
    "print(\"\\n‚úì Complete this challenge to master Pipelines & CV!\")\n",
    "print(\"  Hints:\")\n",
    "print(\"  1. Use features from FEATURES_FULL in baseline model\")\n",
    "print(\"  2. Tune max_depth, learning_rate, n_estimators\")\n",
    "print(\"  3. Use TimeSeriesSplit for CV\")\n",
    "print(\"  4. Evaluate ONCE on test set\")\n",
    "\n",
    "# =============================================================================\n",
    "# SOLUTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Ready to check your solutions?\")\n",
    "print(\"Uncomment the code blocks above and run each exercise!\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tips for success:\n",
    "print(\"üí° Learning Tips:\")\n",
    "print(\"1. Work through exercises in order\")\n",
    "print(\"2. Uncomment code blocks one at a time\")\n",
    "print(\"3. Modify parameters to see effects\")\n",
    "print(\"4. Compare results with expected values\")\n",
    "print(\"5. Ask questions when stuck!\")\n",
    "print(\"\\n‚ú® You've got this! Let's build some models! üèÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
